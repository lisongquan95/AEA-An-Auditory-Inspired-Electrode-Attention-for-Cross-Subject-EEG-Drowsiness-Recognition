{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4f5c95-39e7-49f5-ae16-f09fddbdca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee793ad1-94c4-4162-b61a-2e929349ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AEA(nn.Module):\n",
    "    def __init__(self, E_channels=30, sampleLength=384, i=3, classes=5):\n",
    "        super(AEA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((E_channels, 1))\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d((E_channels, 1))\n",
    "        self.temporal_fc= nn.Conv2d(1, 1, kernel_size=(30, 1), stride=(1,1),padding=(0, 0))\n",
    "        self.fc1 = nn.Conv2d(1, 32, kernel_size=(i, 1), padding=(1, 0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(32, 1, kernel_size=(i, 1), padding=(1, 0))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        temporal_weigh=self.temporal_fc(x)\n",
    "        temporal_weigh=self.relu(temporal_weigh)\n",
    "\n",
    "        # 获取每个电极的全局统计特征\n",
    "        max_val = torch.max(x, dim=-1, keepdim=True)[0]  # 每个电极的最大值\n",
    "        min_val = torch.min(x, dim=-1, keepdim=True)[0]  # 每个电极的最小值\n",
    "        mean_val = torch.mean(x, dim=-1, keepdim=True)  # 每个电极的均值\n",
    "        std_val = torch.std(x, dim=-1, keepdim=True)  # 每个电极的标准差\n",
    "\n",
    "        # 计算基于这些统计量的波动度量\n",
    "        abs_diff = torch.abs(max_val - min_val)  # 基于最大最小值的波动度量\n",
    "\n",
    "        score_avg = self.avg_pool(abs_diff)\n",
    "        out_avg = self.fc1(score_avg)\n",
    "        out_avg = self.relu(out_avg)\n",
    "        out_avg = self.fc2(out_avg)\n",
    "        weight_avg = self.sigmoid(out_avg)\n",
    "\n",
    "        score_max = self.max_pool(abs_diff)\n",
    "        out_max = self.fc1(score_max)\n",
    "        out_max = self.relu(out_max)\n",
    "        out_max = self.fc2(out_max)\n",
    "        weight_max = self.sigmoid(out_max)\n",
    "\n",
    "        # 合并加权池化\n",
    "        weight = (weight_avg + weight_max)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c91bc-3f94-46ea-94f2-4129681eb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEA_ICNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, classes=2, sampleChannel=30, sampleLength=384, N1=16, d=2, kernelLength=64):\n",
    "        super(AEA_ICNN,self).__init__()      \n",
    "\n",
    "        self.AEA = AEA()\n",
    "        self.pointwise = torch.nn.Conv2d(1,16, (sampleChannel, 1))     \n",
    "        self.depthwise = torch.nn.Conv2d(16,32, (1, kernelLength),groups=16)\n",
    "        self.activ = torch.nn.ReLU() \n",
    "        self.batchnorm = torch.nn.BatchNorm2d(32, track_running_stats=False)  # 归一化处理\n",
    "        self.GAP = torch.nn.AvgPool2d((1, sampleLength - kernelLength + 1))  # 平均池化\n",
    "        self.fc = torch.nn.Linear(32, classes)  # 全连接层\n",
    "#         self.softmax_EA = torch.nn.Softmax(dim=0)  #SA需要沿dim=0，沿行；dim=1是沿列累加为1.\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)  # sotmax层\n",
    "       \n",
    "    \n",
    "    def forward(self, inputdata):\n",
    "        attention_vectors = self.AEA(inputdata)\n",
    "        intermediate = inputdata * attention_vectors\n",
    "        intermediate = self.pointwise(intermediate)\n",
    "        intermediate = self.depthwise(intermediate)        \n",
    "        intermediate = self.activ(intermediate)\n",
    "        intermediate = self.batchnorm(intermediate)\n",
    "        intermediate = self.GAP(intermediate)\n",
    "        intermediate = intermediate.view(intermediate.size()[0], -1)\n",
    "        intermediate = self.fc(intermediate)\n",
    "        output = self.softmax(intermediate)\n",
    "\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
